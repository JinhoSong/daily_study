### IT 기술면접 공부하기

---

4. ### 운영체제 OS

	* **프로세스 vs 스레드**

		* **프로그램이란**
			* 어떤 작업을 위해 실행할 수 있는 파일
		* **프로세스란**
			* **컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램**
				* 메모리에 올라와 **실행되고 있는 프로그램의 인스턴스( 독립적인 개체) **
				* 운영체제로부터 시스템 자원을 할당받는 작업의 단위
				* 즉, 동적인 개념으로는 실행된 프로그램을 의미한다.
			* 할당받는 시스템 자원의 예시
				* CPU 시간
				* 운영되기 위해 필요한 주소 공간
				* Code, Data, Stack, Heap의 구조로 되어 있는 독립된 메모리 영역
			* **특징**
				* 프로세스는 독립된 메모리영역을 할당받는다
				* 기본적으로 프로세스당 최소 1개의 **스레드(메인스레드)**를 가지고 있다.
				* 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다.
				* 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신 **(IPC, inter-process communication)**을 사용해야 한다
				* **파이프, 파일 소켓 등을 이용한 방법이 그 예다**
			* **스레드란**
				* 의미
					* 프로세스 내에서 실행되는 여러 흐름의 단위
					* **프로세스의 특정한 수행 경로**
					* 프로세스가 할당받은 자원을 이용하는 실행의 단위
				* **특징**
					* 스레드는 프로세스 내에서 각각 **Stack**만 따로 할당받고 Code, Data, Heap 영역은 공유한다.
					* 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다.
					* 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다.
					* 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있다.
					* 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드도 그 변경 결과를 즉시 볼 수 있다.
			* **자바 스레드란**
				* 일반 스레드와 거의 차이가 없으며, **JVM가 운영체제의 역할을 한다.**
				* 자바에서는 프로세스가 존재하지 않고 스레드만 존재하며, 자바 스레드는 JVM에 의해 스케줄되는 실행 단위 코드 블록이다.
				* 자바에서 스레드 스케줄링은 전적으로 JVM이 한다
					* 스레드가 몇 개 존재하는지
					* 스레드로 실행되는 프로그램 코드의 메모리 위치는 어디인지
					* 스레드의 상태는 무엇인지
					* 스레드 우선순위는 얼마인지
				* **개발자는 자바 스레드로 작동할 스레드 코드를 작성하고, 스레드 코드가 생명을 가지고 실행을 시작하도록 JVM에 요청하는 일만 하면된다.**

	* **멀티 프로스세 대신 멀티 스레드를 사용하는 이유**

		* **프로그램을 여러 개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이다.**
		* **자원의 효율성 증대**
			* 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, **프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어** 자원을 효율적으로 관리할 수 있다.
				* **Context Switching**시 단순히 CPU레지스터 교체 뿐만 아니라 RAM과 CPU 사이의 캐시 메모리에 대한 데이터까지 초기화되므로 오버헤드가 크기 때문
			* 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어들게 된다.
		* **처리 비용 감소 및 응답 시간 단축**
			* 프로세스 간의 IPC 통신 보다 스레드 간의 통신이 비용이 적으므로 작업들 간의 통신의 부담이 줄어든다.
				* 스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문
			* 프로세스 간의 전환 속도보다 스레드 간의 전환 속도가 빠르다.
			* ContextSwitching 시 스레드는 Stack 영역만 처리하기 때문
		* **주의점**
			* **동기화문제**
			* 스레드 간의 자원 공유는 전역변수를 이용하므로 함께 상용할 때 충돌이 발생할 수 있다.

	* **thread safe**

		* 고려해야 될 것

			* 모든 스레드가 데이터 갱신 가능
			* 다른 스레드에 있어서 데이터가 갱신되면 안된다.
			* 데이터를 읽는 동안 다른 스레드는 읽지 못 하도록 해야한다.

		* **Synchronized**

			* 변수 단위나 메소드 단위에 `synchronized`키워드를 추가함으로써, 이를 해결할 수 있다.

		* **ReentrantLock**

			* Lock 인터페이스를 구현한 `ReentrantLock`을 사용함으로써, 이를 해결할 수 있다.

			```java
			import java.util.concurrent.ExecutorService;
			import java.util.concurrent.Executors;
			import java.util.concurrent.locks.ReentrantLock;
			
			public class Main {
			
				private static Integer count = 0;
				private static ReentrantLock rl = new ReentrantLock();
			
				public static void main(String[] args) throws InterruptedException {
			
					ExecutorService service = Executors.newFixedThreadPool(10);
					Runnable runnable = () -> {
						try {
							rl.lock();
							count++;
						} finally {
							rl.unlock();
						}
					};
			
					for (int i = 0; i < 100; i++) {
						service.execute(runnable);
					}
			
					Thread.sleep(2000L);
					service.shutdown();
			
					System.out.println(count);
				}
			```

		* **AtomicInteger**

			* 원자성을 해결하기 위해 사용된다.
			* `AtomicInteger`, `AtomicBoolean`, `AtomicLong` 등이 있다.

		* **`java.util.concurrent`패키지에 멀티 스레드 환경에서 데이터의 원자성을 보장하기 위한 API를 확인가능**

	* **세마포어 뮤텍스**

		* **프로세스 간 메시지를 전송하거나, 공유메모리를 통해 특정 데이터를 공유하게 되는 경우 문제 발생 가능성이 있다.**
		* 공유된 자원에 여러개의 프로세스가 동시에 접근하면 문제가 발생할 확률이 생기므로 공유된 자원 속 하나의 데이터는 한 번에 하나의 프로세스만 접근할 수 있도록 제한해 두어야 한다.
		* **이를 위해 고안된게 세마포어이다**
		* **세마포어 vs 뮤텍스**
			* 세마포어 : 공유된 자원의 데이터를 **여러 프로세스**가 접근하는 것을 막는 것
			* 뮤텍스 : 공유된 자원의 데이터를 **여러 쓰레드**가 접근하는 것을 막는 것
		* **Critical section**
			* 다중 프로그래밍 운영체제에서 여러 프로세스가 데이터를 공유하면서 수행 될 때 **각 프로세스에서 공유 데이터를 엑세스하는 프로그램 코드 부분**을 가리키는 말입니다.
			* 잘못 엑세스하면 시간적인 차이로 잘못된 결과를 만들어 낼 수 있기 때문에 절대로 엑세스 하지 못하도록 해야한다.
			* **임계영역이 만족해야 하는 세 가지 조건을 설명하시오**
				* 1) 상호배제 : 어떤 프로세스가 임계 영역에서 작업 중이면 다른 프로세스는 임계 영역으로 들어 갈 수 없다.
				* 2) 진행 : 임계 영역에 프로세스가 없는 상태에서 여러 프로세스가 들어가려고 할 때는 어떤 프로세스가 들어갈지 적절히 결정해야 한다.
				* 3) 한정 대기 : 다른 프로세스가 임계 영역을 무한정 기다리는 상황을 방지하려면 임계 영역에 한 번 들어갔던 프로세스는 다음에 임계 영역에 다시 들어갈 때 제한을 둔다.
		* **차이점**
			* 세마포어 -> 뮤텍스는 가능
			* 뮤텍스 -> 세마포어는 불가능
			* 뮤텍스 상태가 0,1 두 개 뿐이면 binary 세마포어
			* 세마포어는 소유할 수 없지만, 뮤텍스는 소유가 가능하고 이에 대한 책임을 집니다
			* 뮤텍스의 경우 뮤텍스를 소유하고 있는 쓰레드가 뮤텍스를 해제할 수 있습니다.
			* 세마포어는 소유하지 않은 쓰레드가 해제가능
			* 세마포어는 시스템 범위에 걸쳐있고 파일시스템상의 파일 형태로 존재합니다.
			* 반면 뮤텍스는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 clean up 됩니다.
			* **가장 큰 차이점의 관리하는 동기화 대상의 갯수**
			* **뮤택스는 오직 하나**
			* **세마포어는 동기화 대상이 하나 이상일 때**

	* **스케줄러**

		* 스케줄링이란
			* 프로세스가 생성되어 실행될때 필요한 시스템의 여러자원을 해당 프로세스에게 할당하는 작업을 의미합니다.
			* 프로세스가 생성되어 완료될때까지 프로세스는 여러 종류의 스케줄링 과정을 거치게 됩니다.
			* 스케줄링의 종류는 장기, 중기, 단기
		* 종류
			* **장기**
				*  메모리와 디스크 사이의 스케줄링을 담당
				* 실행할 작업을 준비 큐에서 꺼내 메인 메모리에 적재함
				* **new -> Ready (in memory)**
			* **중기**
				* 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절해주는 스케줄러
				* cpu를 할당받고 프로그램이 실행중 일 때 멀티 프로그래밍 정도에 따라 프로그램들을 관리해주는 역할을 한다 **( swapper)**
				* **ready -> suspended**
			* **단기**
				* CPU와 메모리 사이의 스케줄링을 담당
				* 메인 메몰의 준비 상태에 있는 작업 중 실행할 작업을 선택하여 CPU를 할당.
				* CPU는 프로그램을 실행 시키기 전에 먼저 실행 시키기 위한 데이터 확보가 필요하다
				* 준비 큐에 있는 프로그램들 (프로세스) 중 먼저 도착한 프로세스에게 CPU를 할당시켜준다 == **dispatcher**
				* **ready -> running -> waiting -> ready**
		* **차이점**
			* **실행빈도**
				* **장기 <<<<< 단기**

	* **논리적 주소와 물리적 주소 차이점**

		* **논리적 주소**
			* 주소 프로그램이 실행되는 동안 **CPU**에 의해 생성 된 것을 **논리적 주소**라고한다.
			* **가상주소이다.**
			* 실제 메모리 위치를 액세스 하기 위해 참조로 사용
			* 논리 주소는 **메모리 관리 장치**라는 하드웨어 장치에 의해 해당 물리적 주소에 매핑된다.
		* **물리적 주소**
			* 메모리의 물리적 위치를 식별
			* Memory Management Unit은 해당 논리 주소의 실제 주소를 계산합니다.
			* **사용자는 실제 주소를 결코 취급하지 않는다.**
			* 물리적 주소는 사용자에 의해 해당 논리 주소에 의해 엑세스 됩니다.
		* **주요 차이점**
			* 논리 주소와 실제 주소의 기본적인 차이점은 프로그램의 관점에서 CPU가 논리 주소를 생성한다는 것입니다. 한편, 물리 어드레스는 메모리 유닛에 존재하는 위치이다.
			* 논리 주소는 메모리 장치에 물리적으로 존재하지 않으므로 논리 주소는 **가상 주소**라고도합니다. 물리적 주소는 물리적으로 액세스 할 수있는 **메모리 장치의 위치입니다.**
			* **논리주소는 프로그램 실행동안 CPU에 의해 생성**
			* **물리주소는 MMU에 의해 계산**

	* **내부단편화 외부단편화**

		* **단편화**
			* 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용 하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것이 **단편화**이다
		* **외부단편화**
			* 프로그램을 할당하고 난 다음 아주 작은 크기로 남은 조각들이 생겨 사용할 수 없는 작은 공간들이 많이 생길 수 있다.
			* 허나, 연속적인 공간이 아니라서 할당 못 받는 상황을 **외부단편화**라고한다.
		* **내부단편화**
			* 프로세스가 사용하는 메모리 공간에 포함된 남는 부분
			* 100중 94를 쓰면 6이 내부단편화

	* **페이징과 세그먼테이션**
	
		* 